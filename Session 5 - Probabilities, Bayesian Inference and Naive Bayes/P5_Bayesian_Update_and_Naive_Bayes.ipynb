{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a04e568c",
      "metadata": {
        "id": "a04e568c"
      },
      "source": [
        "# Exercises 5 - Bayesian Update, Bayesian Classification\n",
        "This exercise is composed of two main parts:\n",
        "\n",
        "1. We will see how our **prior beliefs** for hypotheses are **updated** as we see more data by using the **Bayes' Rule**.\n",
        "2. We will use **Naïve Bayes** classification and compare its performance to the similar Logistic Regression classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eee8c8e",
      "metadata": {
        "id": "4eee8c8e"
      },
      "source": [
        "## Bayesian Update"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f060db2",
      "metadata": {
        "id": "1f060db2"
      },
      "source": [
        "A manufacturer sells candies of two flavors: *cherry* and *lime*. All candies are wrapped with the same opaque wrapper, regardless of flavor. So, we cannot see the candy inside. The candies are sold in five types of large bags indistinguishable from the outside and have the following ratios of candies:\n",
        "\n",
        "Bag 1: 100% cherry,  \n",
        "Bag 2: 75% cherry + 25% lime,  \n",
        "Bag 3: 50% cherry + 50% lime,   \n",
        "Bag 4: 25% cherry + 75% lime,  \n",
        "Bag 5: 100% lime.\n",
        "\n",
        "Note: The example in Task 1 is adapted from the book *Artificial Intelligence: A Modern Approach by S.Russell, P.Norvig* (see p802 in 3rd Edition)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae90c87",
      "metadata": {
        "id": "cae90c87"
      },
      "source": [
        "## Task 1\n",
        "The manufacturer says that the bags are distributed with the (0.1, 0.2, 0.4, 0.2, 0.1) ratios, respectively (i.e., Bag 3 is the most common). We are given a bag and not told which type. We draw 10 candies and find out that all of them are of flavour *lime*.\n",
        "\n",
        "Our task is, for each bag, finding the probability that these candies are drawn from that bag. That is, we are looking for:\n",
        "\n",
        "$$\n",
        "P(h_{i} | data) = \\frac{P(data|h_{i}) P(h_{i})}{P(data)} =\n",
        "\\frac{P(data|h_{i}) P(h_{i})}{\\sum_{i}P(data|h_{i}) P(h_{i})}, \\forall i \\in [1..5]\n",
        "$$\n",
        "\n",
        "where, $h_{i}$ is the hypothesis that the candies are drawn from Bag $i$ and $data=lime\\,\\times\\,10$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b03a59",
      "metadata": {
        "id": "46b03a59"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ec4cf2",
      "metadata": {
        "id": "06ec4cf2"
      },
      "source": [
        "We start with creating a class for Bayesian Update. Make sure you understand the class code although you will not be asked to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a08413dc",
      "metadata": {
        "id": "a08413dc"
      },
      "outputs": [],
      "source": [
        "class BayesTableForCandies():\n",
        "    \"\"\"A class for the 'Bayesian Update' of the hypotheses for a candy experiment.\n",
        "\n",
        "    Here, the hypothesis_i is that the candies are drawn from Bag i.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_bags: int, likelihood_lime: List[float], prior: List[float]):\n",
        "        \"\"\"Create\n",
        "            1. A pandas.Dataframe for the Bayesian update of hypotheses;\n",
        "            2. A pandas.Series to track history of posteriors of hypotheses.\n",
        "\n",
        "        n_bags: Number of bags\n",
        "        likelihood_lime: List of probabilities of drawing a lime candy from each bag\n",
        "        prior: The probability of choosing each bag (This probability can be assumed or given to us a priori)\n",
        "        \"\"\"\n",
        "        assert n_bags==len(likelihood_lime)==len(prior)  # Argument validation\n",
        "        assert np.sum(prior, dtype=np.float32)==1.  # Priors should sum up to 1\n",
        "        # Create the Bayes table\n",
        "        self.table = pd.DataFrame(index=[f\"Bag {i}\" for i in range(1, n_bags + 1)])\n",
        "        self.table[\"likelihood_lime\"] = likelihood_lime\n",
        "        self.table[\"likelihood_cherry\"] = 1. - self.table[\"likelihood_lime\"]\n",
        "        self.table[\"prior\"] = prior\n",
        "        self.table[\"posterior\"] = [.0] * n_bags\n",
        "        # Initialize the posterior history for each bag. Initial `prior` is the first record.\n",
        "        self.posterior_history = self.table[\"prior\"].apply(lambda x: [x]).rename(\"posteriors\")\n",
        "\n",
        "\n",
        "    def bayesian_update(self, candy: str) -> np.ndarray:\n",
        "        \"\"\"Get a candy and update the posteriors for the hypotheses with the Bayes' Rule.\"\"\"\n",
        "        assert candy in [\"L\", \"C\"]  # Check a valid candy is given. L: lime, C: cherry.\n",
        "        if self.table[\"posterior\"].any():  # If this is not the first update\n",
        "            self.table[\"prior\"] = self.table[\"posterior\"]  # last posterior -> new prior\n",
        "        likelihood = self.table[\"likelihood_lime\"] if candy == \"L\" else self.table[\"likelihood_cherry\"]\n",
        "        self.table[\"posterior\"] = likelihood * self.table[\"prior\"]\n",
        "        self.table[\"posterior\"] = self.table[\"posterior\"] / self.table[\"posterior\"].sum()  # normalize the posterior to [0., 1.]\n",
        "        # Append the new posteriors to the corresponding bag's history\n",
        "        for ix, posterior in self.table[\"posterior\"].items():\n",
        "            self.posterior_history.loc[ix].append(posterior)\n",
        "\n",
        "        return self.table[\"posterior\"].to_numpy()  # updated posteriors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d636fce",
      "metadata": {
        "id": "2d636fce"
      },
      "outputs": [],
      "source": [
        "# Create the Bayes Table for Task 1.\n",
        "btable = BayesTableForCandies(n_bags=5, likelihood_lime=[0, .25, .50, .75, 1.], prior=[.1, .2, .4, .2, .1])\n",
        "btable.table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64848758",
      "metadata": {
        "id": "64848758"
      },
      "source": [
        "> Note that neither of the *likelihood* columns adds up to one. Each likelihood is the probability of the $data$ conditioned on a different hypothesis $h_i$. There is no reason for them to add up to one. That's why we call $P(data|h_{i})$ the *likelihood of $h_i$* and _**not** the probability_ of it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321f7c8d",
      "metadata": {
        "id": "321f7c8d"
      },
      "source": [
        "Then, we make Bayesian Updates of our beliefs for the observed 10 *lime* candies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0cfaa7",
      "metadata": {
        "id": "5c0cfaa7"
      },
      "outputs": [],
      "source": [
        "data_observations = \"L\" * 10\n",
        "for candy in data_observations:\n",
        "    new_posteriors = btable.bayesian_update(candy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7baad4b6",
      "metadata": {
        "id": "7baad4b6"
      },
      "source": [
        "The answer, that is, the posterior probability of each bag after observing 10 *lime* candies are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04894295",
      "metadata": {
        "id": "04894295"
      },
      "outputs": [],
      "source": [
        "new_posteriors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ab8b70",
      "metadata": {
        "id": "e4ab8b70"
      },
      "source": [
        "After these observations, we have reason to believe that we are given Bag 5 as it has the highest posterior probability. Note that we can be (100%) certain that we are not holding Bag 1 as it has 0 posterior probability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d151b80",
      "metadata": {
        "id": "4d151b80"
      },
      "source": [
        "Now, let's plot the posteriors for each update and see how our beliefs for the hypotheses changed after each update.\n",
        "> Just have an idea what the function does, you will use it as-is but you will not be asked to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8056f475",
      "metadata": {
        "id": "8056f475"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44159bd",
      "metadata": {
        "id": "f44159bd"
      },
      "outputs": [],
      "source": [
        "def plot_posterior_history(history: pd.Series, data: str, markers=(',', '+', '.', '*', 's')):\n",
        "    \"\"\"Plots the posterior history of each of the hypotheses.\"\"\"\n",
        "    plt.figure().gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    marker = itertools.cycle(markers)\n",
        "    n_observations = len(data)\n",
        "    n_each_candy = Counter(data)\n",
        "    for ix, posteriors in history.items():\n",
        "        plt.plot(np.arange(n_observations + 1), posteriors, label=ix, marker=next(marker))\n",
        "    plt.xlim([0, n_observations])\n",
        "    plt.ylim([0., 1.])\n",
        "    plt.title(f\"Observations: {dict(n_each_candy)}\")\n",
        "    plt.xlabel(\"Number of candy observations\")\n",
        "    plt.ylabel(\"Posterior probability of hypothesis\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17e3a4da",
      "metadata": {
        "id": "17e3a4da"
      },
      "outputs": [],
      "source": [
        "plot_posterior_history(btable.posterior_history, data_observations)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935daac1",
      "metadata": {
        "id": "935daac1"
      },
      "source": [
        "We see in the above figure that the hypotheses start with their initial priors. As we observe data, our (posterior) beliefs about the hypotheses change. After three *lime* candies, Bag 5 becomes the most likely hypothesis. And continued observation of the same flavor makes the posterior probability of Bag 5 gradually converge to `1.0`. In other words, after each consecutive *lime* candy pick, we start to believe more that we are holding the Bag 5 that has 100% *lime*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7c54d21",
      "metadata": {
        "id": "b7c54d21"
      },
      "source": [
        "<font color=blue>We draw a new candy (i.e., the eleventh) and find out this time that it is a *cherry*. What would be the posterior probability for Bag 5 now?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4a54b39",
      "metadata": {
        "id": "a4a54b39"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a9ce94",
      "metadata": {
        "id": "e1a9ce94"
      },
      "source": [
        "<font color=blue>We continue to draw nine more candies and, to our surprise, all are *cherries*! Which bag would have the highest posterior now? Which bag(s) would have posterior(s) that is(are) exactly 0.0?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51ebf7bf",
      "metadata": {
        "id": "51ebf7bf"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c46474a",
      "metadata": {
        "id": "8c46474a"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7134375",
      "metadata": {
        "id": "e7134375"
      },
      "source": [
        "We will conduct two experiments in parallel, again with 5 bags. In the first experiment, the *lime* likelihoods and bags' prior probabilties are the same as in [Task 1](#Task-1). In the second experiment, the *lime* likelihoods are also the same, but we are not provided with the bags' prior probabilities. Therefore, we assume that the bags are distributed with *uniform prior* probability (i.e., each bag has the same prior probability).\n",
        "\n",
        "<font color=blue>Create two new Bayes tables --`btable1` and `btable2`-- for these two experiments, respectively.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09491dbd",
      "metadata": {
        "id": "09491dbd"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57989984",
      "metadata": {
        "id": "57989984"
      },
      "source": [
        "We observe 5 lime and 20 cherry candies in both experiments.\n",
        "\n",
        "<font color=blue>Carry out Bayesian update with `btable1` and `btable2` for these observations and print the posterior probabilities for both tables.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f29a28",
      "metadata": {
        "id": "f5f29a28"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a40271",
      "metadata": {
        "id": "86a40271"
      },
      "source": [
        "<font color=blue>Plot the posterior histories for both experiments.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36088469",
      "metadata": {
        "id": "36088469"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db84f96a",
      "metadata": {
        "id": "db84f96a"
      },
      "source": [
        "<font color=blue>After having many observations, do you think our prior beliefs matter much for the posteriors? Explain why.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd0a4e5a",
      "metadata": {
        "id": "fd0a4e5a"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ed7288",
      "metadata": {
        "id": "68ed7288"
      },
      "source": [
        "# Naïve Bayes classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's remember how Naïve Bayes assumption helps us reduce the number of paramaters to estimate in Bayesian classification.\n",
        "\n",
        "Given:\n",
        "\n",
        "* $K = 2$ classes\n",
        "* $n = 3$ features\n",
        "*\tEach feature $X_i$ has $J_i = 4$  discrete values\n",
        "\n",
        "<font color=blue>Find the *total number of independent parameters* to estimate in Bayesian classification *without* and *with* Naïve Bayes assumption. (Hint: You need to calculate the number of both likelihood and prior parameters to find the total.)</font>"
      ],
      "metadata": {
        "id": "nupEQNKlslRm"
      },
      "id": "nupEQNKlslRm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HyfzpqsNthX-"
      },
      "id": "HyfzpqsNthX-"
    },
    {
      "cell_type": "markdown",
      "id": "3c75f2f2",
      "metadata": {
        "id": "3c75f2f2"
      },
      "source": [
        "## Import data\n",
        "We will work with the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) that we saw previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d9d699",
      "metadata": {
        "id": "f0d9d699"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris(as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e53fa18",
      "metadata": {
        "id": "7e53fa18"
      },
      "source": [
        "Let's explore the data before classification tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834bd6e3",
      "metadata": {
        "id": "834bd6e3"
      },
      "outputs": [],
      "source": [
        "# Features have continuous values (float)\n",
        "iris.data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ccb8cf",
      "metadata": {
        "id": "32ccb8cf"
      },
      "outputs": [],
      "source": [
        "# Classes are discrete values\n",
        "iris.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "124b6913",
      "metadata": {
        "id": "124b6913"
      },
      "source": [
        "Let's choose two features to work with, for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6381b973",
      "metadata": {
        "id": "6381b973"
      },
      "outputs": [],
      "source": [
        "feat1 , feat2 = iris.feature_names[2:4]  # 'petal length (cm)', 'petal width (cm)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90c00ee1",
      "metadata": {
        "id": "90c00ee1"
      },
      "outputs": [],
      "source": [
        "X = iris.data[[feat1 , feat2]]\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd25ad9",
      "metadata": {
        "id": "0cd25ad9"
      },
      "outputs": [],
      "source": [
        "# Import multivariate Gaussian distribution to model continuous-valued features for exploration\n",
        "from scipy.stats import multivariate_normal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "370a0f2e",
      "metadata": {
        "id": "370a0f2e"
      },
      "source": [
        "Now, we define the functions to be used in plotting henceforth.\n",
        "> Just have an idea what the functions do, you will not be asked to modify the plotting code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b39b0f4",
      "metadata": {
        "id": "5b39b0f4"
      },
      "outputs": [],
      "source": [
        "# Set the color map for plots\n",
        "cmap = plt.cm.tab10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25bd405",
      "metadata": {
        "id": "e25bd405"
      },
      "outputs": [],
      "source": [
        "def plt_limit(plt: plt, X: pd.DataFrame):\n",
        "    \"\"\"Set plot's margins\"\"\"\n",
        "    plt.xlim([math.floor(X.iloc[:, 0].min()), math.ceil(X.iloc[:, 0].max())])\n",
        "    plt.ylim([math.floor(X.iloc[:, 1].min()), math.ceil(X.iloc[:, 1].max())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac310db",
      "metadata": {
        "id": "6ac310db"
      },
      "outputs": [],
      "source": [
        "def quantize(X_i: pd.Series, sigmas: int=3, n: int=101) -> np.ndarray:\n",
        "    \"\"\"Quantize a pandas Series w.r.t. to its mean and standard deviation.\n",
        "\n",
        "    X_i: i^th input feature\n",
        "    sigmas: Number of std deviation\n",
        "    n: Number of intervals\n",
        "    \"\"\"\n",
        "    mean, std = X_i.mean(), X_i.std()\n",
        "    low = mean - sigmas * std\n",
        "    up = mean + sigmas * std\n",
        "    samples = np.linspace(low, up, n)\n",
        "\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d00fc7",
      "metadata": {
        "id": "e4d00fc7"
      },
      "outputs": [],
      "source": [
        "def plot_contour2D(X: pd.DataFrame, y: pd.Series, y_names: List[str], nb: bool=False, **options):\n",
        "    \"\"\"Plot contour lines of the bivariate distribution of the two features for each class.\n",
        "\n",
        "    X: Input data with two features\n",
        "    y: Input target\n",
        "    y_names: Target class names\n",
        "    nb: If True, the bivariate distribution is estimated w.r.t. Naïve Bayes' assumption\n",
        "    options: Passed to the `matlplotlib.pyplot.contour` function\n",
        "    \"\"\"\n",
        "    assert X.shape[1] == 2\n",
        "    assert X.shape[0] == y.shape[0]\n",
        "    df = pd.concat([X, y], axis=1)\n",
        "    grouped = df.groupby(df.columns[-1])  # Group input data by target, i.e., the last column\n",
        "    for target, group in grouped:\n",
        "        X1, X2 = group.iloc[:, 0], group.iloc[:, 1]\n",
        "        plt.scatter(X1, X2, c=cmap(np.full(X1.size, target)), label=y_names[target])  # Plot the data points\n",
        "        mean = group.iloc[:, 0:2].mean()  # X1 and X2\n",
        "        cov = group.iloc[:, 0:2].cov()\n",
        "        if nb:\n",
        "            cov.iloc[0, 1] = cov.iloc[1, 0] = 0.\n",
        "        multinorm = multivariate_normal(mean, cov)\n",
        "        X1_q, X2_q = quantize(X1), quantize(X2)\n",
        "        X1, X2 = np.meshgrid(X1_q, X2_q)\n",
        "        pos = np.dstack((X1, X2))\n",
        "        plt.contour(X1, X2, multinorm.pdf(pos), linewidths=1, **options)  # Plot the contours for the `target` class\n",
        "    plt.xlabel(X.columns[0])\n",
        "    plt.ylabel(X.columns[1])\n",
        "    plt.title(\"Density Contours \" + (\"w.r.t. Naïve Bayes\" if nb else \"w/ covariance of the features\"))\n",
        "    plt_limit(plt, X)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f49968a",
      "metadata": {
        "id": "4f49968a"
      },
      "outputs": [],
      "source": [
        "# Plot bivariate Gussian densities for the select features\n",
        "plot_contour2D(X, y, iris.target_names, alpha=0.8, levels=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93d0e42a",
      "metadata": {
        "id": "93d0e42a"
      },
      "source": [
        "<font color=blue>Interpret the diagonally stretched density contour lines for these two features.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751c0721",
      "metadata": {
        "id": "751c0721"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d9f169",
      "metadata": {
        "id": "c8d9f169"
      },
      "outputs": [],
      "source": [
        "# Plot densities for the features w.r.t. Naïve Bayes' assumption\n",
        "plot_contour2D(X, y, iris.target_names, nb=True, alpha=0.8, levels=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "614a9d9f",
      "metadata": {
        "id": "614a9d9f"
      },
      "source": [
        "<font color=blue>Why are the axes of the density contour lines parallel to the features' axes in the case of Naïve Bayes? i.e., Why did we add the hard-coded line in the `plot_contour` function for NB?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea7d67c",
      "metadata": {
        "id": "cea7d67c"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e271bcd",
      "metadata": {
        "id": "0e271bcd"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef1bc9c5",
      "metadata": {
        "id": "ef1bc9c5"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b5bfb3",
      "metadata": {
        "id": "d9b5bfb3"
      },
      "source": [
        "We define a function to visualize the decision boundaries for a two-feature dataset.\n",
        "> Just have an idea what the function does, you will not be asked to modify the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e48cf87",
      "metadata": {
        "id": "9e48cf87"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundaries2D(classifier: object, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Plots the decision boundaries and training and test data points.\"\"\"\n",
        "    X = pd.concat([X_train, X_test], axis=0)\n",
        "    disp = DecisionBoundaryDisplay.from_estimator(\n",
        "        classifier, X,\n",
        "        response_method=\"predict\",\n",
        "        xlabel=X.columns[0], ylabel=X.columns[1],\n",
        "        cmap=cmap,\n",
        "        alpha=0.1,\n",
        "        grid_resolution=200)\n",
        "    # Plot Training data points\n",
        "    disp.ax_.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=cmap(y_train), alpha=0.2,\n",
        "                     marker=\"o\", label=\"Training\")\n",
        "    # Plot Test data points\n",
        "    miss = y_test != classifier.predict(X_test)\n",
        "    disp.ax_.scatter(X_test[~miss].iloc[:, 0], X_test[~miss].iloc[:, 1], c=cmap(y_test[~miss]), edgecolor=\"k\",\n",
        "                     marker=\"o\", label=\"Test correctly classified\")\n",
        "    disp.ax_.scatter(X_test[miss].iloc[:, 0], X_test[miss].iloc[:, 1], c=cmap(y_test[miss]), edgecolor=\"r\",\n",
        "                     marker=\"D\", label=\"Test misclassified\")\n",
        "    plt_limit(plt, X)\n",
        "    plt.suptitle(f\"Decision boundaries of the {classifier.__class__.__name__} classifier\")\n",
        "    plt.title(\"with Training and Test data points\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c85070d",
      "metadata": {
        "id": "1c85070d"
      },
      "source": [
        "We create Training and Test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49e3887",
      "metadata": {
        "id": "f49e3887"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a731e27",
      "metadata": {
        "id": "3a731e27"
      },
      "source": [
        "First, let's use Logistic Regression's performance on this dataset. (Actually, this is known as the *Multinomial* Logistic Regression as there are more than two classes.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7447b74",
      "metadata": {
        "id": "e7447b74"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(max_iter=400)\n",
        "# Fit the model and predict the test data\n",
        "y_pred_log_reg = log_reg.fit(X_train, y_train).predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24223684",
      "metadata": {
        "id": "24223684"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred_log_reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d371010",
      "metadata": {
        "id": "0d371010"
      },
      "source": [
        "Not bad. Let's see the decision boundaries learned by this classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a292973",
      "metadata": {
        "id": "6a292973"
      },
      "outputs": [],
      "source": [
        "plot_decision_boundaries2D(log_reg, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4544188b",
      "metadata": {
        "id": "4544188b"
      },
      "source": [
        "Note the linear boundaries of Logistic Regression and one mislabeled test instance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e74b78e",
      "metadata": {
        "id": "9e74b78e"
      },
      "source": [
        "<font color=blue>Use the same `train` and `test` datasets to fit a Gaussian Naïve Bayes classifier (`GaussianNB`) and make predictions, respectively.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8ec2d1",
      "metadata": {
        "id": "7d8ec2d1"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4093dde",
      "metadata": {
        "id": "a4093dde"
      },
      "source": [
        "<font color=blue>What is the accuracy score for the Gaussian Naïve Bayes?</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a293944b",
      "metadata": {
        "id": "a293944b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3081013",
      "metadata": {
        "id": "e3081013"
      },
      "source": [
        "<font color=blue>Plot the decision boundaries of this Gaussian Naïve Bayes classifier like we did for the Logistic Regression above.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8abedd3b",
      "metadata": {
        "id": "8abedd3b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4605fba",
      "metadata": {
        "id": "a4605fba"
      },
      "source": [
        "<font color=blue>Are the decision boundaries different for both classifiers? Why or why not?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bed1b72",
      "metadata": {
        "id": "1bed1b72"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "328219a0",
      "metadata": {
        "id": "328219a0"
      },
      "source": [
        "Now, let's compare the performances of the two classifiers on the whole dataset (all features) with cross validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25fee377",
      "metadata": {
        "id": "25fee377"
      },
      "outputs": [],
      "source": [
        "X = iris.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d11f29",
      "metadata": {
        "id": "f9d11f29"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
        "\n",
        "gnb2 = GaussianNB()\n",
        "log_reg2 = LogisticRegression(max_iter=400)\n",
        "\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n",
        "scores_gnb = cross_val_score(gnb2, X, y, cv=cv)\n",
        "scores_log_reg = cross_val_score(log_reg2, X, y, cv=cv)\n",
        "print(\"Cross validation (accuracy) scores:\")\n",
        "print(\"    Gaussian NB -> mean:\", scores_gnb.mean(), \"std:\", scores_gnb.std())\n",
        "print(\"    Logistic Regression -> mean:\", scores_log_reg.mean(), \"std:\", scores_log_reg.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4b6f19d",
      "metadata": {
        "id": "c4b6f19d"
      },
      "source": [
        "<font color=blue>It is known that when the Gaussian NB modeling assumption holds, Logistic Regression and Gaussian NB converge toward identical classifiers\\*. Interpret why Gaussian NB slightly underperformed Log Reg for this dataset.</font><small>\\* _see_ the reference for T. Mitchell in the Lecture 5's Resources slides.</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc10b07",
      "metadata": {
        "id": "8bc10b07"
      },
      "source": [
        "---\n",
        "\n",
        "*YOUR RESPONSE HERE*\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "uab",
      "language": "python",
      "name": "uab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}